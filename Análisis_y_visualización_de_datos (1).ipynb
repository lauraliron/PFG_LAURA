{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx_CnawVlSs3"
      },
      "source": [
        "# Visualización de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzGpXiw9tQRj"
      },
      "source": [
        "##Limpieza de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KxWkjGmla5j"
      },
      "source": [
        "En esta parte del trabajo analizaremos la base de datos con la que trabajaremos a lo largo del proyecto. Nuestro objetivo es comprender las características principales de los datos, como el número total de pacientes, la detección de valores atípicos (outliers), la distribución de pacientes según su localización y los meses en los que se registra una mayor afluencia a urgencias. Además, realizaremos ajustes en las columnas y añadiremos nuevas variables para refinar la base de datos con la que trabajaremos a lo largo del proyecto.\n",
        "\n",
        "Este análisis preliminar nos permitirá obtener una visión clara y detallada de los datos, lo que será fundamental para extraer conclusiones significativas. A partir de este conocimiento, podremos avanzar hacia la etapa de modelado y realizar predicciones mediante el uso de algoritmos avanzados, como XGBoost.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6cNGJaAjfaz"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.13.3' requires the ipykernel package.\n",
            "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
            "\u001b[1;31mCommand: 'c:/Users/usuario/AppData/Local/Programs/Python/Python313/python.exe -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "from geopy.geocoders import Nominatim\n",
        "from geopy.exc import GeocoderTimedOut\n",
        "from meteostat import Stations, Hourly\n",
        "from datetime import datetime, timedelta\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import calendar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2s-GD4X_RLWZ"
      },
      "source": [
        "####**1. Lectura del archivo.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5I9S7I7VReI9"
      },
      "source": [
        "Como primer paso, cargamos el archivo .csv, mostramos los primeros datos y analizamos sus principales características. Las columnas con las que contamos son las siguientes:\n",
        "\n",
        "* Fecha de atención: Indica el día, mes y año en que el paciente acudió a urgencias.\n",
        "* Día de la semana: Nombre del día de la semana correspondiente a la fecha de atención.\n",
        "* Nivel de triaje: Representa el nivel de urgencia de atención del paciente.\n",
        "* Zona Básica de Salud: Zona de referencia médica asignada al paciente.\n",
        "* Ámbito de procedencia: Clasificación del ámbito del paciente, ya sea urbano o rural.\n",
        "* Hospital: Nombre del hospital donde fue atendido el paciente.\n",
        "* Área: Área en la que se encuentra el hospital.\n",
        "* Provincia: Provincia en la que se encuentra el hospital.\n",
        "* Edad: Edad del paciente en años.\n",
        "* Sexo: Sexo del paciente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uA-R19gGIFZ1",
        "outputId": "63a927ab-0275-4670-e865-ec8036a625df"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"urgencias-hospitalarias-atendidas.csv\", sep=\";\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ICnoDixmFjb"
      },
      "source": [
        "Lo primero que haremos será convertir las columnas Nivel de triaje y Edad a valores numéricos, asegurando que cualquier dato no válido se transforme en NaN, mientras que Zona Básica de Salud, Hospital, Área y Provincia serán convertidas en variables categóricas. Además, Sexo y Ámbito de procedencia se normalizarán a valores binarios y se transformarán en enteros, asignando NaN a los datos que no cumplan con los valores esperados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJzOwygjk9aK",
        "outputId": "e7ef48c1-b7f6-4886-db82-20b7f34f8f8c"
      },
      "outputs": [],
      "source": [
        "df[[\"Nivel de triaje\", \"Edad\"]] = df[[\"Nivel de triaje\", \"Edad\"]].apply(\n",
        "    pd.to_numeric, errors=\"coerce\"\n",
        ")\n",
        "\n",
        "columnas_categoricas = [\"Zona Básica de Salud\", \"Hospital\", \"Área\", \"Provincia\"]\n",
        "df[columnas_categoricas] = df[columnas_categoricas].astype(\"string\")\n",
        "\n",
        "df[\"Sexo\"] = df[\"Sexo\"].map({\"Hombre\": 1, \"Mujer\": 0}).astype(\"Int64\")\n",
        "df[\"Ámbito de procedencia\"] = (\n",
        "    df[\"Ámbito de procedencia\"].map({\"Urbano\": 1, \"Rural\": 0}).astype(\"Int64\")\n",
        ")\n",
        "\n",
        "df.rename(columns={\"Sexo\": \"Hombre\", \"Ámbito de procedencia\": \"Urbano\"}, inplace=True)\n",
        "\n",
        "print(\"Datos limpios y convertidos correctamente:\")\n",
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P89jJIG1ocVL"
      },
      "source": [
        "####**2.Completar base de datos**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AQcyNucooN-"
      },
      "source": [
        "A continuación, añadiremos nuevas columnas que pueden ser de utilidad para nuestro análisis, como la indicación de días festivos, la temperatura y si ha llovido o no, entre otros factores relevantes. Antes de ello, comenzaremos creando una columna que contenga la fecha completa junto con el día, la hora, el año y el mes, lo que nos permitirá disponer de una estructura temporal más detallada para futuros estudios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okMjY0LUprQy",
        "outputId": "61005207-b04b-45d1-c9ca-5b904e7813c1"
      },
      "outputs": [],
      "source": [
        "print(\"Valores NaN en 'Fecha de atención':\", df[\"Fecha de atención\"].isna().sum())\n",
        "print(\"Valores NaN en 'Hora':\", df[\"Hora\"].isna().sum())\n",
        "\n",
        "print(\"Formatos únicos en 'Fecha de atención':\")\n",
        "print(df[\"Fecha de atención\"].dropna().astype(str).str[:10].value_counts().head(10))\n",
        "\n",
        "print(\"Valores problemáticos en 'Hora':\")\n",
        "print(\n",
        "    df[~df[\"Hora\"].astype(str).str.match(r\"^\\d{2}:\\d{2}$\", na=False)][\"Hora\"].unique()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DSzvneAqTsi",
        "outputId": "47cb6abd-1fef-424f-d9fd-1f10b5a5d1f8"
      },
      "outputs": [],
      "source": [
        "df[\"Fecha de atención\"] = pd.to_datetime(df[\"Fecha de atención\"], errors=\"coerce\")\n",
        "\n",
        "# Corregir \"Hora\" eliminando valores incorrectos\n",
        "df[\"Hora\"] = df[\"Hora\"].astype(str)\n",
        "df.loc[df[\"Hora\"] == \":\", \"Hora\"] = np.nan  # Reemplazar \":\" por NaN\n",
        "df.loc[~df[\"Hora\"].str.match(r\"^\\d{2}:\\d{2}$\", na=False), \"Hora\"] = (\n",
        "    np.nan\n",
        ")  # Eliminar formatos inválidos\n",
        "df[\"Hora\"].fillna(\"00:00\", inplace=True)  # Asigna \"00:00\" a los valores NaN restantes\n",
        "\n",
        "# Asegurar que \"Hora\" tenga solo HH:MM (sin segundos)\n",
        "df[\"Hora\"] = pd.to_datetime(df[\"Hora\"], format=\"%H:%M\", errors=\"coerce\").dt.strftime(\n",
        "    \"%H:%M\"\n",
        ")\n",
        "\n",
        "df[\"Fecha completa\"] = pd.to_datetime(\n",
        "    df[\"Fecha de atención\"].dt.strftime(\"%Y-%m-%d\") + \" \" + df[\"Hora\"],\n",
        "    format=\"%Y-%m-%d %H:%M\",\n",
        "    errors=\"coerce\",\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\" Fechas inválidas detectadas después de la corrección: {df['Fecha completa'].isna().sum()}\"\n",
        ")\n",
        "print(df[[\"Fecha de atención\", \"Día de la semana\", \"Hora\", \"Fecha completa\"]].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1GMauSbwJjo"
      },
      "source": [
        "Una vez creada la columna que contiene la fecha completa, transformamos el tiempo en una función sinusoidal para representar su circularidad temporal. Esto es especialmente útil en análisis de series temporales y modelos predictivos, ya que evita que el modelo interprete las variables temporales como lineales.  \n",
        "\n",
        "Al aplicar funciones seno (`sin`) y coseno (`cos`), conseguimos que valores como la hora del día, el mes o el día del año conserven su periodicidad. De este modo, el modelo entiende que, por ejemplo, la hora 23 y la hora 0 están cerca, o que enero y diciembre son meses consecutivos en el ciclo anual. Esto mejora la precisión de los modelos y facilita la detección de patrones temporales en los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8u40_UAq_fD"
      },
      "outputs": [],
      "source": [
        "df[\"Hora del día\"] = df[\"Fecha completa\"].dt.hour  # 0-23\n",
        "df[\"Día del año\"] = df[\"Fecha completa\"].dt.dayofyear  # 1-365\n",
        "df[\"Mes del año\"] = df[\"Fecha completa\"].dt.month  # 1-12\n",
        "\n",
        "# Transformación sinusoidal\n",
        "df[\"Hora_sin\"] = np.sin(2 * np.pi * df[\"Hora del día\"] / 24)\n",
        "df[\"Hora_cos\"] = np.cos(2 * np.pi * df[\"Hora del día\"] / 24)\n",
        "\n",
        "df[\"Día_sin\"] = np.sin(2 * np.pi * df[\"Día del año\"] / 365)\n",
        "df[\"Día_cos\"] = np.cos(2 * np.pi * df[\"Día del año\"] / 365)\n",
        "\n",
        "df[\"Mes_sin\"] = np.sin(2 * np.pi * df[\"Mes del año\"] / 12)\n",
        "df[\"Mes_cos\"] = np.cos(2 * np.pi * df[\"Mes del año\"] / 12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60gMCYh2xuD9"
      },
      "source": [
        "Ahora identificaremos los días festivos en la comunidad de Castilla y León, añadiendo una columna binaria que tomará el valor 1 cuando la fecha corresponda a un festivo/domingo y 0 en caso contrario. Además, incorporaremos una nueva columna para indicar la estación del año en la que se encuentra cada fecha, lo que nos permitirá analizar posibles variaciones en los datos según la temporada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "oDM-7TS_omND",
        "outputId": "5c977584-29a7-42ef-e10c-64999ed5385a"
      },
      "outputs": [],
      "source": [
        "# Lista de festivos en Castilla y León\n",
        "festivos = [\n",
        "    \"2021-01-01\",\n",
        "    \"2021-01-06\",\n",
        "    \"2021-04-01\",\n",
        "    \"2021-04-02\",\n",
        "    \"2021-04-23\",\n",
        "    \"2021-05-01\",\n",
        "    \"2021-08-16\",\n",
        "    \"2021-10-12\",\n",
        "    \"2021-11-01\",\n",
        "    \"2021-12-06\",\n",
        "    \"2021-12-08\",\n",
        "    \"2021-12-25\",\n",
        "    \"2022-01-01\",\n",
        "    \"2022-01-06\",\n",
        "    \"2022-04-14\",\n",
        "    \"2022-04-15\",\n",
        "    \"2022-04-23\",\n",
        "    \"2022-05-02\",\n",
        "    \"2022-08-15\",\n",
        "    \"2022-10-12\",\n",
        "    \"2022-11-01\",\n",
        "    \"2022-12-06\",\n",
        "    \"2022-12-08\",\n",
        "    \"2022-12-26\",\n",
        "    \"2023-01-02\",\n",
        "    \"2023-01-06\",\n",
        "    \"2023-04-06\",\n",
        "    \"2023-04-07\",\n",
        "    \"2023-05-01\",\n",
        "    \"2023-07-25\",\n",
        "    \"2023-08-15\",\n",
        "    \"2023-10-12\",\n",
        "    \"2023-11-01\",\n",
        "    \"2023-12-06\",\n",
        "    \"2023-12-08\",\n",
        "    \"2023-12-25\",\n",
        "]\n",
        "festivos = pd.to_datetime(festivos)\n",
        "\n",
        "# Crear la columna 'Festivo' considerando también los domingos\n",
        "df[\"Festivo\"] = df[\"Fecha completa\"].apply(\n",
        "    lambda x: 1 if (x in festivos or x.weekday() == 6) else 0\n",
        ")\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjM8Ip-Lqs4k"
      },
      "outputs": [],
      "source": [
        "def obtener_estacion(fecha):\n",
        "    if fecha is pd.NaT:\n",
        "        return None  # Si la fecha es NaN, devolver None\n",
        "\n",
        "    mes = fecha.month\n",
        "    dia = fecha.day\n",
        "\n",
        "    if (mes == 12 and dia >= 21) or (mes in [1, 2]) or (mes == 3 and dia < 20):\n",
        "        return \"Invierno\"\n",
        "    elif (mes == 3 and dia >= 20) or (mes in [4, 5]) or (mes == 6 and dia < 21):\n",
        "        return \"Primavera\"\n",
        "    elif (mes == 6 and dia >= 21) or (mes in [7, 8]) or (mes == 9 and dia < 23):\n",
        "        return \"Verano\"\n",
        "    else:\n",
        "        return \"Otoño\"\n",
        "\n",
        "\n",
        "df[\"Estación del Año\"] = df[\"Fecha completa\"].apply(obtener_estacion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWtqt7pHyQOH"
      },
      "source": [
        "A continuación, inicializaremos el geocodificador para obtener la latitud y longitud de cada hospital. Para optimizar este proceso, en lugar de extraer las coordenadas fila por fila, identificaremos los hospitales únicos presentes en el DataFrame y obtendremos sus coordenadas a partir de esa lista."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "AUSsdRmRrO-j",
        "outputId": "c1712628-3899-4ed0-a619-a13b0b21a5be"
      },
      "outputs": [],
      "source": [
        "geolocator = Nominatim(user_agent=\"hospital_locator\")\n",
        "\n",
        "hospitales_unicos = df[\"Hospital\"].dropna().unique()\n",
        "\n",
        "\n",
        "def obtener_coordenadas(hospital):\n",
        "    try:\n",
        "        location = geolocator.geocode(hospital + \", España\", timeout=10)\n",
        "        if location:\n",
        "            return (location.latitude, location.longitude)\n",
        "        else:\n",
        "            return (None, None)\n",
        "    except GeocoderTimedOut:\n",
        "        return (None, None)\n",
        "\n",
        "\n",
        "coordenadas_hospitales = {\n",
        "    hospital: obtener_coordenadas(hospital) for hospital in hospitales_unicos\n",
        "}\n",
        "\n",
        "df_coordenadas = pd.DataFrame.from_dict(\n",
        "    coordenadas_hospitales, orient=\"index\", columns=[\"Latitud\", \"Longitud\"]\n",
        ").reset_index()\n",
        "df_coordenadas.rename(columns={\"index\": \"Hospital\"}, inplace=True)\n",
        "\n",
        "df = df.merge(df_coordenadas, on=\"Hospital\", how=\"left\")\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxTXHSbuck4s"
      },
      "source": [
        "Comprobaremos si existe algún hospital en el que no hayamos obtenido las coordenadas, identificando aquellos registros que aún presentan valores nulos en las columnas de latitud y longitud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NK8pm7n_rSyM",
        "outputId": "0ac19371-a6b1-465a-8218-7956b7da5c12"
      },
      "outputs": [],
      "source": [
        "df[\"Latitud\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0704ZV2wrVJo",
        "outputId": "cb73bb7d-85da-4e97-e552-825b4c560b42"
      },
      "outputs": [],
      "source": [
        "df[\"Longitud\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUBzdUYLrXfF",
        "outputId": "e7c46d67-34b2-4980-849c-bd18f83ddee3"
      },
      "outputs": [],
      "source": [
        "hospitales_sin_coordenadas = df[df[[\"Latitud\", \"Longitud\"]].isna().any(axis=1)][\n",
        "    [\"Hospital\", \"Latitud\", \"Longitud\"]\n",
        "]\n",
        "\n",
        "hospitales_sin_coordenadas[\"Hospital\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdAefM_xc2SW"
      },
      "source": [
        "Hemos localizado las coordenadas faltantes a través de fuentes en internet y procederemos a asignarlas manualmente a cada hospital correspondiente en el DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWhlxX7jrZ6f"
      },
      "outputs": [],
      "source": [
        "coordenadas_manual = {\n",
        "    \"H.C.U. Valladolid\": (41.655903, -4.718669),\n",
        "    \"H.U. Río Hortega\": (41.628797, -4.711461),\n",
        "}\n",
        "df[\"Hospital\"] = df[\"Hospital\"].str.strip()\n",
        "\n",
        "df[\"Latitud\"] = df.apply(\n",
        "    lambda row: coordenadas_manual[row[\"Hospital\"]][0]\n",
        "    if row[\"Hospital\"] in coordenadas_manual\n",
        "    else row[\"Latitud\"],\n",
        "    axis=1,\n",
        ")\n",
        "df[\"Longitud\"] = df.apply(\n",
        "    lambda row: coordenadas_manual[row[\"Hospital\"]][1]\n",
        "    if row[\"Hospital\"] in coordenadas_manual\n",
        "    else row[\"Longitud\"],\n",
        "    axis=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDM7lg6BQWVB",
        "outputId": "4e5042cd-9498-45e3-e1a9-543c94e0eb94"
      },
      "outputs": [],
      "source": [
        "# Filtrar filas donde Latitud o Longitud sean NaN\n",
        "nan_coords = df[df[[\"Latitud\", \"Longitud\"]].isna().any(axis=1)]\n",
        "\n",
        "# Mostrar las filas con NaN en Latitud o Longitud\n",
        "print(nan_coords[[\"Hospital\", \"Latitud\", \"Longitud\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIBqdYCMdhFS"
      },
      "source": [
        "###**COMENTARLO, CODIGO ACTUALIZADO**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apvlBE2-udLI"
      },
      "source": [
        "Asignar el registro más cercano"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "8t4ZuYonOukM",
        "outputId": "ee2dbc25-402a-4797-a53a-9cdcae08ac37"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "from meteostat import Stations, Hourly\n",
        "\n",
        "# OBTENER ESTACIONES CERCANAS A CADA HOSPITAL ---\n",
        "# Crear un DataFrame con hospitales únicos y sus coordenadas\n",
        "hospitales_unicos = df[[\"Hospital\", \"Latitud\", \"Longitud\"]].drop_duplicates().copy()\n",
        "\n",
        "\n",
        "# Función para obtener la estación meteorológica más cercana\n",
        "def obtener_estacion(lat, lon):\n",
        "    stations = Stations()\n",
        "    station = stations.nearby(lat, lon).fetch(1)\n",
        "    return station.index[0] if not station.empty else None\n",
        "\n",
        "\n",
        "# Asignar estación a cada hospital\n",
        "hospitales_unicos[\"Estacion_hosp\"] = hospitales_unicos.apply(\n",
        "    lambda row: obtener_estacion(row[\"Latitud\"], row[\"Longitud\"]), axis=1\n",
        ")\n",
        "\n",
        "# Verificar que hospitales_unicos es un DataFrame válido\n",
        "print(\"Tipo de hospitales_unicos:\", type(hospitales_unicos))\n",
        "print(\"Columnas en hospitales_unicos:\", hospitales_unicos.columns.tolist())\n",
        "\n",
        "# Hacer merge con df para agregar la estación más cercana a cada hospital\n",
        "df = df.merge(hospitales_unicos, on=[\"Hospital\", \"Latitud\", \"Longitud\"], how=\"left\")\n",
        "\n",
        "# AGRUPAR HORAS ÚNICAS POR HOSPITAL PARA OPTIMIZAR LA DESCARGA DE DATOS CLIMÁTICOS ---\n",
        "hospitales_horas_unicas = df[[\"Estacion_hosp\", \"Fecha completa\"]].drop_duplicates()\n",
        "\n",
        "# Almacenar datos meteorológicos por estación y hora\n",
        "resultados_clima = []\n",
        "\n",
        "for estacion in hospitales_horas_unicas[\"Estacion_hosp\"].dropna().unique():\n",
        "    fechas_unicas = hospitales_horas_unicas[\n",
        "        hospitales_horas_unicas[\"Estacion_hosp\"] == estacion\n",
        "    ][\"Fecha completa\"]\n",
        "\n",
        "    # Definir rango de fechas a descargar\n",
        "    fecha_inicio = fechas_unicas.min()\n",
        "    fecha_fin = fechas_unicas.max() + timedelta(days=1)\n",
        "\n",
        "    # Obtener datos meteorológicos solo para esas fechas y estación\n",
        "    datos_clima = Hourly(estacion, fecha_inicio, fecha_fin).fetch()\n",
        "\n",
        "    if not datos_clima.empty:\n",
        "        datos_clima = datos_clima[[\"temp\", \"prcp\"]].reset_index()\n",
        "        datos_clima[\"Ha llovido\"] = (datos_clima[\"prcp\"] > 0).astype(int)\n",
        "        datos_clima[\"Estacion_hosp\"] = estacion\n",
        "        resultados_clima.append(datos_clima)\n",
        "\n",
        "# Unir todos los datos meteorológicos en un solo DataFrame\n",
        "clima_df = pd.concat(resultados_clima, ignore_index=True)\n",
        "\n",
        "# LIMPIEZA Y ORDENADO DE DATOS PARA MERGE ---\n",
        "# Convertir fechas a datetime\n",
        "df[\"Fecha completa\"] = pd.to_datetime(df[\"Fecha completa\"], errors=\"coerce\")\n",
        "clima_df[\"time\"] = pd.to_datetime(clima_df[\"time\"], errors=\"coerce\")\n",
        "\n",
        "# Eliminar valores NaN en claves principales\n",
        "df = df.dropna(subset=[\"Fecha completa\", \"Estacion_hosp\"])\n",
        "clima_df = clima_df.dropna(subset=[\"time\", \"Estacion_hosp\"])\n",
        "\n",
        "# Eliminar duplicados en df\n",
        "df = df.drop_duplicates(subset=[\"Estacion_hosp\", \"Fecha completa\"])\n",
        "\n",
        "# Eliminar duplicados en clima_df\n",
        "clima_df = (\n",
        "    clima_df.groupby([\"Estacion_hosp\", \"time\"])\n",
        "    .agg({\"temp\": \"mean\", \"Ha llovido\": \"max\"})\n",
        "    .reset_index()\n",
        ")\n",
        "\n",
        "# Ordenar ambos DataFrames para el merge_asof\n",
        "df = df.sort_values(by=[\"Estacion_hosp\", \"Fecha completa\"]).reset_index(drop=True)\n",
        "clima_df = clima_df.sort_values(by=[\"Estacion_hosp\", \"time\"]).reset_index(drop=True)\n",
        "\n",
        "# REALIZAR EL MERGE ASOF ---\n",
        "df = pd.merge_asof(\n",
        "    df,\n",
        "    clima_df[[\"time\", \"temp\", \"Ha llovido\", \"Estacion_hosp\"]],\n",
        "    left_on=\"Fecha completa\",\n",
        "    right_on=\"time\",\n",
        "    by=\"Estacion_hosp\",\n",
        "    direction=\"nearest\",\n",
        ")\n",
        "\n",
        "# Eliminar la columna 'time' si ya no es necesaria\n",
        "df = df.drop(columns=[\"time\"])\n",
        "\n",
        "# ✅ Mostrar resultados finales\n",
        "print(df[[\"Hospital\", \"Fecha completa\", \"temp\", \"Ha llovido\"]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWyTKj6ahL0o"
      },
      "outputs": [],
      "source": [
        "df[\"Ha llovido\"].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2TE6HrWh3aW"
      },
      "source": [
        "####**3. Estudio de Nan.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYzlCrc7YCrR"
      },
      "source": [
        "Contamos la cantidad de datos presentes en cada columna para identificar posibles datos faltantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899
        },
        "id": "s1S3EACkWC4l",
        "outputId": "165f3d01-a46e-4a1e-d4fc-87faa6f199b8"
      },
      "outputs": [],
      "source": [
        "df.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJesAjkoYKO0"
      },
      "source": [
        "Observamos que no todas las columnas contienen la misma cantidad de datos, por lo que procederemos a identificar qué variables presentan valores nulos (NaN). Esto nos permitirá decidir si estos valores faltantes impactarán en nuestro análisis y, por lo tanto, si será necesario eliminarlos, o si podrán ser ignorados sin comprometer los resultados de nuestra investigación.\n",
        "\n",
        "Por ahora, no sabemos cómo pueden influir los valores nulos en variables como la procedencia y la zona básica de salud, por lo que no eliminaremos esas filas en esta etapa. En cuanto a las variables como edad y sexo, estas podrían tener un impacto significativo en nuestro análisis, por lo que se evaluarán más adelante antes de tomar una decisión definitiva."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "Vp3JHThcYnFk",
        "outputId": "d99cf0b0-72f7-44b7-aa0f-48d2737561d6"
      },
      "outputs": [],
      "source": [
        "missing_data = df.isna().sum()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "missing_data.plot(\n",
        "    kind=\"bar\", color=\"#123456\", edgecolor=\"black\"\n",
        ")  # Ajusta el color aquí\n",
        "plt.title(\"Datos Faltantes por Columna\", fontsize=16)\n",
        "plt.xlabel(\"Columnas\", fontsize=12)\n",
        "plt.ylabel(\"Cantidad de Datos Faltantes\", fontsize=12)\n",
        "plt.xticks(rotation=45, ha=\"right\", fontsize=10)\n",
        "plt.grid(axis=\"y\", alpha=0.7, linestyle=\"--\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F3n4bqCpH2p",
        "outputId": "728ab368-fccf-4ecd-e995-840ffc8148e8"
      },
      "outputs": [],
      "source": [
        "na_por_columna = df.isna().sum()\n",
        "\n",
        "na_totales = df.isna().sum().sum()\n",
        "\n",
        "print(\"Valores NaN por columna:\")\n",
        "print(na_por_columna)\n",
        "print(\"\\nNúmero total de valores NaN en el DataFrame:\", na_totales)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VX6s5hINa4gh"
      },
      "source": [
        "Vamos a analizar si los datos faltantes coinciden entre las columnas \"Zona Básica de Salud\" y \"Urbano\", así como entre \"Edad\" y \"Hombre\". Más adelante, revisaremos los datos faltantes en \"Nivel de Triaje\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h_2txi1Zabv",
        "outputId": "f0c9f260-0d86-4911-87c5-c44c2f25537c"
      },
      "outputs": [],
      "source": [
        "na_coinciden = (df[\"Zona Básica de Salud\"].isna() == df[\"Urbano\"].isna()).all()\n",
        "\n",
        "print(\"¿Coinciden los NaN entre 'Zona Básica de Salud' y 'Urbano'?\", na_coinciden)\n",
        "\n",
        "nan_coinciden = (df[\"Edad\"].isna() == df[\"Hombre\"].isna()).all()\n",
        "\n",
        "print(\"¿Coinciden los NaN entre 'Edad' y 'Hombre'?\", nan_coinciden)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Szy_VX32dySe"
      },
      "source": [
        "Hemos comprobado que coinciden los datos faltantes, ahora evaluaremos si los valores de Zona Básica de Salud y Urbano pueden derivarse directamente del hospital, lo que podría hacerlas redundantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iFUfD-Pdaq0",
        "outputId": "a39e2aa4-de37-437c-ea4f-6a497d3782ad"
      },
      "outputs": [],
      "source": [
        "zona_ambito_hospital = df.groupby([\"Área\", \"Hospital\"])[\n",
        "    [\"Zona Básica de Salud\", \"Urbano\"]\n",
        "].nunique()\n",
        "print(\"Niveles únicos por hospital:\\n\", zona_ambito_hospital)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ElfNzqkciXy"
      },
      "source": [
        "No es posible deducir la Zona Básica de Salud (ZBS) ni el ámbito de procedencia únicamente a partir del hospital, ya que un mismo hospital atiende a pacientes provenientes de diferentes ZBS y ámbitos. Tampoco podemos determinarlo exclusivamente a partir del área. Sin embargo, este análisis nos permite identificar qué hospitales están asociados a cada área, lo cual es útil para comprender mejor la distribución geográfica de la atención hospitalaria.\n",
        "\n",
        "También vamos a ver como se asocian las áreas con cada provincia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "DjDwWCoHpoH_",
        "outputId": "f9e8e9e4-a46f-463f-f5b5-2ae6f339057a"
      },
      "outputs": [],
      "source": [
        "provincias_analisis = df.groupby(\"Provincia\").agg({\"Área\": lambda x: x.unique()})\n",
        "\n",
        "provincias_analisis = provincias_analisis.reset_index()\n",
        "\n",
        "provincias_analisis.columns = [\"Provincia\", \"Áreas\"]\n",
        "\n",
        "provincias_analisis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8S_-kHqiMfL",
        "outputId": "93aff3e3-8df9-445a-a39b-397b4d93703f"
      },
      "outputs": [],
      "source": [
        "duplicados = df.duplicated()\n",
        "\n",
        "total_duplicados = duplicados.sum()\n",
        "\n",
        "print(f\"Total de filas completamente duplicadas: {total_duplicados}\")\n",
        "\n",
        "if total_duplicados > 0:\n",
        "    print(\"Filas duplicadas:\")\n",
        "    print(df[duplicados])\n",
        "else:\n",
        "    print(\"No hay filas completamente duplicadas en el DataFrame.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCRjYj-7VB74"
      },
      "source": [
        "Para decidir si se deben eliminar los valores faltantes en *Nivel de Triaje*, agruparemos la cantidad de estos valores por mes con el objetivo de identificar posibles patrones temporales en los datos faltantes. Este análisis permitirá determinar si la ausencia de datos está concentrada en ciertos periodos específicos o si se distribuye de manera uniforme a lo largo del tiempo. Según los resultados, se evaluará si la eliminación de estos registros podría afectar la representatividad del análisis o si sería más adecuado considerar otras estrategias, como la imputación de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "ox88Pd2MVDV6",
        "outputId": "9d7734e2-cf13-4dac-e25f-e8e96b699b25"
      },
      "outputs": [],
      "source": [
        "df[\"Año_Mes\"] = df[\"Fecha completa\"].dt.to_period(\"M\")\n",
        "\n",
        "nan_triaje_por_mes = df[df[\"Nivel de triaje\"].isna()].groupby(\"Año_Mes\").size()\n",
        "\n",
        "# Contar el total de registros por mes para calcular proporciones\n",
        "total_por_mes = df.groupby(\"Año_Mes\").size()\n",
        "\n",
        "proporcion_nan = (nan_triaje_por_mes / total_por_mes) * 100\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Gráfico 1: Cantidad de NaN por mes\n",
        "nan_triaje_por_mes.plot(kind=\"bar\", color=\"#123456\", alpha=1, ax=axes[0])\n",
        "axes[0].set_title('Cantidad de valores faltantes en \"Nivel de Triaje\" por mes')\n",
        "axes[0].set_xlabel(\"Mes\")\n",
        "axes[0].set_ylabel(\"Cantidad de NaN\")\n",
        "axes[0].tick_params(axis=\"x\", rotation=45)\n",
        "\n",
        "# Gráfico 2: Proporción de NaN por mes\n",
        "proporcion_nan.plot(kind=\"bar\", color=\"#123456\", alpha=0.7, ax=axes[1])\n",
        "axes[1].set_title('Proporción de valores faltantes en \"Nivel de Triaje\" por mes (%)')\n",
        "axes[1].set_xlabel(\"Mes\")\n",
        "axes[1].set_ylabel(\"Proporción de NaN (%)\")\n",
        "axes[1].tick_params(axis=\"x\", rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xIZA0c4sYY2q"
      },
      "source": [
        "A través de estos gráficos, podemos observar una mejora en la calidad de los registros de los datos. A inicios de 2021, la cantidad de valores faltantes superó los 20,000 en algunos meses, mientras que hacia finales de 2023 esta cantidad disminuyó a menos de 8,000.\n",
        "\n",
        "Dado este comportamiento, la mejor opción podría ser eliminar los registros faltantes correspondientes a los meses de 2021, con el fin de evitar sesgos derivados de datos incompletos durante ese periodo.\n",
        "\n",
        "En cuanto a los datos faltantes de 2022, dado que la proporción es significativamente menor y se observa una estabilización en la calidad del registro, podríamos optar por mantenerlos, imputarlos o eliminarlos, dependiendo de la importancia de estos valores en el análisis y del impacto que su ausencia pueda tener en los resultados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAht8SJFiDTR"
      },
      "source": [
        "####**4. Análisis de pacientes por año.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNqwIJUWg8Sa"
      },
      "source": [
        "En esta sección analizaremos cómo se distribuyen las distintas variables. En primer lugar, nos interesa examinar cómo se distribuyen los datos a lo largo del tiempo. Para ello, creamos un gráfico que muestra la cantidad de los datos por año.\n",
        "\n",
        "Estudiar esto es relevante debido  debido al estado de alarma por COVID-19. Este análisis nos permitirá identificar si los datos de ese año podrían introducir sesgos en nuestros resultados y, en caso necesario, considerar estrategias para manejarlos adecuadamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "STuTXzs7qVMO",
        "outputId": "cec3f34b-03d3-49f1-948e-c8fbc4111945"
      },
      "outputs": [],
      "source": [
        "df[\"Fecha de atención\"] = pd.to_datetime(df[\"Fecha de atención\"], errors=\"coerce\")\n",
        "\n",
        "df[\"Año\"] = df[\"Fecha de atención\"].dt.year\n",
        "\n",
        "conteo_por_año = df[\"Año\"].value_counts().sort_index()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(conteo_por_año.index, conteo_por_año.values, color=\"#123456\")\n",
        "plt.title(\"Cantidad de datos por año\", fontsize=16)\n",
        "plt.xlabel(\"Año\", fontsize=14)\n",
        "plt.ylabel(\"Cantidad de datos\", fontsize=14)\n",
        "plt.xticks(conteo_por_año.index, rotation=45)\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBgdv_CghDlB"
      },
      "source": [
        "En 2021 se observa una menor cantidad de datos, lo que podría indicar que durante ciertos meses no se registraron datos en nuestra base de datos. Procederemos a comprobarlo, ya que inicialmente se esperaba un resultado contrario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "lVUrEhrjqVAT",
        "outputId": "592939bf-5c9a-43cc-e9c9-cc70c7d559e9"
      },
      "outputs": [],
      "source": [
        "df[\"Fecha de atención\"] = pd.to_datetime(df[\"Fecha de atención\"], errors=\"coerce\")\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for year, color in zip([2021, 2022, 2023], [\"red\", \"blue\", \"green\"]):\n",
        "    # Filtrar los datos del año\n",
        "    datos_por_semana = (\n",
        "        df[df[\"Fecha de atención\"].dt.year == year]\n",
        "        .groupby(df[\"Fecha de atención\"].dt.isocalendar().week)\n",
        "        .size()\n",
        "    )\n",
        "\n",
        "    plt.scatter(\n",
        "        datos_por_semana.index,\n",
        "        datos_por_semana.values,\n",
        "        label=f\"Año {year}\",\n",
        "        color=color,\n",
        "        s=50,\n",
        "        alpha=0.7,\n",
        "    )\n",
        "\n",
        "# Personalización del gráfico\n",
        "plt.title(\"Cantidad de datos por semana para cada año\", fontsize=16)\n",
        "plt.xlabel(\"Semana del año\", fontsize=14)\n",
        "plt.ylabel(\"Cantidad de datos\", fontsize=14)\n",
        "plt.xticks(range(1, 54))  # Semanas de 1 a 53\n",
        "plt.legend(title=\"Año\", fontsize=12)\n",
        "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNPnSa5EYrDR"
      },
      "source": [
        "Verificamos que, efectivamente, durante todas las semanas del año 2021 se han registrado datos en nuestra base de datos. Sin embargo, para entender mejor la disminución en la cantidad total de datos de ese año, vamos a analizar si todos los hospitales tuvieron registros consistentes durante 2021. Esto nos permitirá identificar si la reducción de datos se debe a la falta de registros en ciertos hospitales o a algún otro motivo relacionado con la recopilación de información."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkBsTgJdbumg",
        "outputId": "e5741b55-a6fd-4309-a190-bd1a8d2f3503"
      },
      "outputs": [],
      "source": [
        "# Filtrar hospitales sin valores nulos\n",
        "hospitales_2021 = sorted(\n",
        "    df.loc[df[\"Fecha de atención\"].dt.year == 2021, \"Hospital\"].dropna().unique()\n",
        ")\n",
        "hospitales_totales = sorted(df[\"Hospital\"].dropna().unique())\n",
        "\n",
        "print(\"Hospitales en 2021:\")\n",
        "print(\"\\n\".join(hospitales_2021))\n",
        "print(f\"\\nTotal de hospitales en 2021: {len(hospitales_2021)}\\n\")\n",
        "\n",
        "print(\"Hospitales totales:\")\n",
        "print(\"\\n\".join(hospitales_totales))\n",
        "print(f\"\\nTotal de hospitales totales: {len(hospitales_totales)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XhoA7JQWVuD",
        "outputId": "ad34f997-6319-47eb-d62d-4bc11b17e272"
      },
      "outputs": [],
      "source": [
        "datos_faltantes_2021 = df[df[\"Fecha de atención\"].dt.year == 2021].isna().sum()\n",
        "print(\"Datos faltantes en 2021:\\n\", datos_faltantes_2021)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58V4dRxLVsG-"
      },
      "source": [
        "Vemos que hay registros en todos los hospitales durante 2021, por lo que descartamos que la falta de datos esté relacionada con la ausencia de registros en algún hospital específico. Sin embargo, sigue siendo extraño que, a pesar de la pandemia de COVID-19, haya un menor número de registros durante este año. Para explorar más a fondo este fenómeno, investigaremos cuál es el mes con menos pacientes en 2021 y trataremos de extraer conclusiones a partir de esta información."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrQYB2gZgisJ"
      },
      "source": [
        "Vamos a analizar la cantidad de pacientes que acudieron a urgencias por mes en cada año, con el objetivo de identificar a partir de qué mes los datos de 2021 comienzan a asemejarse a los de 2022 y 2023. Esto nos permitirá determinar desde qué punto podemos considerar que la base de datos es representativa y adecuada para su análisis sin verse afectada por posibles anomalías relacionadas con la pandemia de COVID-19."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "ER9OVf7VaRow",
        "outputId": "105ea825-0edb-4839-829b-6e0b110e9299"
      },
      "outputs": [],
      "source": [
        "# Contar la cantidad de pacientes por mes en cada año\n",
        "pacientes_por_mes_2021 = (\n",
        "    df[df[\"Fecha de atención\"].dt.year == 2021][\"Fecha de atención\"]\n",
        "    .dt.month.value_counts()\n",
        "    .sort_index()\n",
        ")\n",
        "pacientes_por_mes_2022 = (\n",
        "    df[df[\"Fecha de atención\"].dt.year == 2022][\"Fecha de atención\"]\n",
        "    .dt.month.value_counts()\n",
        "    .sort_index()\n",
        ")\n",
        "pacientes_por_mes_2023 = (\n",
        "    df[df[\"Fecha de atención\"].dt.year == 2023][\"Fecha de atención\"]\n",
        "    .dt.month.value_counts()\n",
        "    .sort_index()\n",
        ")\n",
        "\n",
        "# Crear un array con los meses del año (1 a 12)\n",
        "meses = np.arange(1, 13)\n",
        "\n",
        "# Crear el gráfico de líneas\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(\n",
        "    meses, pacientes_por_mes_2021, marker=\"o\", linestyle=\"-\", label=\"2021\", color=\"blue\"\n",
        ")\n",
        "plt.plot(\n",
        "    meses, pacientes_por_mes_2022, marker=\"o\", linestyle=\"-\", label=\"2022\", color=\"red\"\n",
        ")\n",
        "plt.plot(\n",
        "    meses,\n",
        "    pacientes_por_mes_2023,\n",
        "    marker=\"o\",\n",
        "    linestyle=\"-\",\n",
        "    label=\"2023\",\n",
        "    color=\"green\",\n",
        ")\n",
        "\n",
        "# Configuración del gráfico\n",
        "plt.title(\"Comparación de Pacientes por Mes (2021-2023)\", fontsize=16)\n",
        "plt.xlabel(\"Mes\", fontsize=14)\n",
        "plt.ylabel(\"Número de Pacientes\", fontsize=14)\n",
        "plt.xticks(\n",
        "    meses,\n",
        "    [\n",
        "        \"Enero\",\n",
        "        \"Febrero\",\n",
        "        \"Marzo\",\n",
        "        \"Abril\",\n",
        "        \"Mayo\",\n",
        "        \"Junio\",\n",
        "        \"Julio\",\n",
        "        \"Agosto\",\n",
        "        \"Septiembre\",\n",
        "        \"Octubre\",\n",
        "        \"Noviembre\",\n",
        "        \"Diciembre\",\n",
        "    ],\n",
        "    rotation=45,\n",
        ")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw943Im6ils4"
      },
      "source": [
        "Vemos que a partir de mayo los datos de 2021 comienzan a asemejarse a los de los años siguientes, lo que sugiere que a partir de ese mes la base de datos puede considerarse representativa y sin anomalías significativas relacionadas con la pandemia de COVID-19. Para asegurarnos de ello, realizaremos un análisis cuantitativo mediante la comparación de las diferencias porcentuales entre los datos de 2021 y los de 2022 y 2023.\n",
        "\n",
        "A través de este análisis, podremos verificar si el punto de inflexión observado en el gráfico anterior se mantiene en una comparación más detallada, confirmando si mayo es efectivamente el mes a partir del cual los datos de 2021 pueden utilizarse sin sesgos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624
        },
        "id": "2TJGT_ulaThT",
        "outputId": "94b41e56-927b-4fac-9ea7-c6df7fdbb89a"
      },
      "outputs": [],
      "source": [
        "# Crear un DataFrame con los datos de pacientes por mes en cada año\n",
        "datos_pacientes = pd.DataFrame(\n",
        "    {\n",
        "        \"Mes\": np.arange(1, 13),\n",
        "        \"2021\": pacientes_por_mes_2021,\n",
        "        \"2022\": pacientes_por_mes_2022,\n",
        "        \"2023\": pacientes_por_mes_2023,\n",
        "    }\n",
        ")\n",
        "\n",
        "# Calcular diferencias porcentuales con respecto a 2021\n",
        "datos_pacientes[\"Dif_2021_vs_2022\"] = (\n",
        "    (datos_pacientes[\"2022\"] - datos_pacientes[\"2021\"]) / datos_pacientes[\"2022\"]\n",
        ") * 100\n",
        "datos_pacientes[\"Dif_2021_vs_2023\"] = (\n",
        "    (datos_pacientes[\"2023\"] - datos_pacientes[\"2021\"]) / datos_pacientes[\"2023\"]\n",
        ") * 100\n",
        "\n",
        "# Graficar la diferencia porcentual mes a mes\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(\n",
        "    datos_pacientes[\"Mes\"],\n",
        "    datos_pacientes[\"Dif_2021_vs_2022\"],\n",
        "    marker=\"o\",\n",
        "    linestyle=\"-\",\n",
        "    label=\"Diferencia 2021 vs 2022\",\n",
        "    color=\"red\",\n",
        ")\n",
        "plt.plot(\n",
        "    datos_pacientes[\"Mes\"],\n",
        "    datos_pacientes[\"Dif_2021_vs_2023\"],\n",
        "    marker=\"o\",\n",
        "    linestyle=\"-\",\n",
        "    label=\"Diferencia 2021 vs 2023\",\n",
        "    color=\"green\",\n",
        ")\n",
        "\n",
        "# Configuración del gráfico\n",
        "plt.axvline(x=5, color=\"black\", linestyle=\"--\", label=\"Mayo\")  # Línea vertical en junio\n",
        "plt.title(\"Diferencia Porcentual de Pacientes (2021 vs 2022 y 2023)\", fontsize=16)\n",
        "plt.xlabel(\"Mes\", fontsize=14)\n",
        "plt.ylabel(\"Diferencia Porcentual (%)\", fontsize=14)\n",
        "plt.xticks(\n",
        "    np.arange(1, 13),\n",
        "    [\n",
        "        \"Enero\",\n",
        "        \"Febrero\",\n",
        "        \"Marzo\",\n",
        "        \"Abril\",\n",
        "        \"Mayo\",\n",
        "        \"Junio\",\n",
        "        \"Julio\",\n",
        "        \"Agosto\",\n",
        "        \"Septiembre\",\n",
        "        \"Octubre\",\n",
        "        \"Noviembre\",\n",
        "        \"Diciembre\",\n",
        "    ],\n",
        "    rotation=45,\n",
        ")\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7gV1zdPnWnR"
      },
      "source": [
        "El gráfico confirma que en mayo se produce un punto de inflexión en la diferencia porcentual de pacientes entre 2021 y los otros dos años (2022 y 2023). Hasta abril, las diferencias son significativamente altas, indicando que la cantidad de registros en 2021 era considerablemente menor en comparación con los otros años. Sin embargo, a partir de mayo, estas diferencias disminuyen de manera constante hasta estabilizarse en valores más bajos, lo que sugiere que la tendencia de pacientes en 2021 comienza a asemejarse a la de 2022 y 2023.\n",
        "\n",
        "Este análisis nos indica que los datos de 2021 anteriores a mayo podrían estar sesgados y no reflejar correctamente la demanda de urgencias debido a la pandemia. Por lo tanto, una decisión adecuada para trabajar con esta base de datos sería considerar únicamente los registros a partir de mayo de 2021 en adelante, asegurándonos así de que los datos utilizados sean más comparables y representativos de la realidad hospitalaria post-pandemia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Czn-u2l6pdeS"
      },
      "source": [
        "####**5. Estudio las diferentes variables**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkJEdYri4K3U"
      },
      "source": [
        "Ahora vamos a analizar las variables para verificar que todas tengan valores coherentes y consistentes. Nos enfocaremos en la variable \"Edad\" como ejemplo, observando sus máximos, mínimos, media y otros estadísticos relevantes. Este análisis nos permitirá identificar y eliminar datos que no sean reales, como valores negativos, extremadamente altos o que no correspondan con expectativas razonables. Este proceso es esencial para garantizar la calidad y la integridad de los datos antes de realizar cualquier análisis más profundo o tomar decisiones basadas en ellos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "1Tv63Yj73oud",
        "outputId": "87425389-b280-49ec-b295-bd5ade8d7bcd"
      },
      "outputs": [],
      "source": [
        "df[\"Edad\"].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnYv8VB-4fFf"
      },
      "source": [
        "A través de este análisis, observamos que la media de edad de los pacientes es de 47 años. Sin embargo, también encontramos que el valor mínimo de edad es -1 año, lo cual no es lógico, y el máximo de edad es de 122 años. Al investigar un poco más, encontramos que la persona más longeva del mundo tiene 117 años, lo que indica que estos valores extremos no tienen sentido y son probablemente errores en los datos. Por lo tanto, procederemos a eliminar estos outliers para garantizar la calidad y coherencia de la información antes de continuar con el análisis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "nuC5UlXy4y-O",
        "outputId": "b47d6ff6-af4a-494f-9909-3e87ce6afeb7"
      },
      "outputs": [],
      "source": [
        "edades_fuera_de_rango = df[(df[\"Edad\"] < 0) | (df[\"Edad\"] > 117)]\n",
        "\n",
        "edades_fuera_de_rango.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "3TL2ev8c34M7",
        "outputId": "7a97f22c-0645-41bf-aaa1-29a4ef1aad8e"
      },
      "outputs": [],
      "source": [
        "df[\"Edad\"].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAnoY7zGGND9"
      },
      "source": [
        "Una vez hemos limpiado la variable de edad, vamos a proceder a ver los dias de la semana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRXpFNwrjPYq",
        "outputId": "812990db-d14b-4018-ab5b-45a2a47c3e04"
      },
      "outputs": [],
      "source": [
        "dias_esperados = [\n",
        "    \"LUNES\",\n",
        "    \"MARTES\",\n",
        "    \"MIÉRCOLES\",\n",
        "    \"JUEVES\",\n",
        "    \"VIERNES\",\n",
        "    \"SÁBADO\",\n",
        "    \"DOMINGO\",\n",
        "]\n",
        "\n",
        "dias_unicos = df[\"Día de la semana\"].unique()\n",
        "\n",
        "print(\"Días únicos en la columna:\", dias_unicos)\n",
        "\n",
        "dias_no_validos = [dia for dia in dias_unicos if dia not in dias_esperados]\n",
        "\n",
        "if dias_no_validos:\n",
        "    print(\"Días no válidos encontrados:\", dias_no_validos)\n",
        "else:\n",
        "    print(\"Todos los días están escritos de forma adecuada.\")\n",
        "\n",
        "filas_dias_no_validos = df[df[\"Día de la semana\"].isin(dias_no_validos)]\n",
        "\n",
        "if not filas_dias_no_validos.empty:\n",
        "    print(\"Filas con días no válidos:\")\n",
        "    print(filas_dias_no_validos.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ2r1yr_1xem"
      },
      "source": [
        "A continuación, el código verifica que no existan fechas inválidas, como el 30 de febrero, asegurando que todas las fechas en el DataFrame sean correctas y correspondan a días reales dentro de cada mes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8H93UVPy57Lf",
        "outputId": "48770b02-27b8-4633-e21b-1ee9c6eee9e2"
      },
      "outputs": [],
      "source": [
        "df[\"Fecha de atención\"] = pd.to_datetime(df[\"Fecha de atención\"], errors=\"coerce\")\n",
        "\n",
        "fechas_invalidas = df[df[\"Fecha de atención\"].isna()]\n",
        "\n",
        "if fechas_invalidas.empty:\n",
        "    print(\"Todas las fechas son válidas.\")\n",
        "else:\n",
        "    print(\"Fechas no válidas encontradas:\")\n",
        "    print(fechas_invalidas)\n",
        "\n",
        "df[\"Día\"] = df[\"Fecha de atención\"].dt.day\n",
        "df[\"Mes\"] = df[\"Fecha de atención\"].dt.month\n",
        "df[\"Año\"] = df[\"Fecha de atención\"].dt.year\n",
        "\n",
        "\n",
        "def verificar_dias_invalidos(df):\n",
        "    problemas = []\n",
        "    for año in df[\"Año\"].unique():\n",
        "        for mes in df[\"Mes\"].unique():\n",
        "            # Obtener último día del mes para el año dado\n",
        "            ultimo_dia = calendar.monthrange(año, mes)[1]\n",
        "            # Filtrar filas donde el día excede el último día del mes\n",
        "            dias_invalidos = df[\n",
        "                (df[\"Año\"] == año) & (df[\"Mes\"] == mes) & (df[\"Día\"] > ultimo_dia)\n",
        "            ]\n",
        "            if not dias_invalidos.empty:\n",
        "                problemas.append(dias_invalidos)\n",
        "    return problemas\n",
        "\n",
        "\n",
        "problemas_dias = verificar_dias_invalidos(df)\n",
        "\n",
        "if problemas_dias:\n",
        "    print(\"Se encontraron fechas con días fuera de rango:\")\n",
        "    for problema in problemas_dias:\n",
        "        print(problema)\n",
        "else:\n",
        "    print(\"No se encontraron días fuera de rango.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7KX32ef2Cts"
      },
      "source": [
        "Ahora realizamos la misma verificación con las horas, asegurándonos de que todas estén en un formato válido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krpGJBZmHQ2c",
        "outputId": "b3612337-627c-4775-ef9b-fe09c203e3e0"
      },
      "outputs": [],
      "source": [
        "df[\"Hora\"] = df[\"Hora\"].astype(str)\n",
        "\n",
        "\n",
        "# Función para verificar horas válidas\n",
        "def es_hora_valida(hora):\n",
        "    try:\n",
        "        # Intentar convertir la hora al formato datetime.time\n",
        "        pd.to_datetime(hora, format=\"%H:%M\").time()\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "\n",
        "# Aplicar la función para identificar horas inválidas\n",
        "df[\"Hora válida\"] = df[\"Hora\"].apply(es_hora_valida)\n",
        "\n",
        "# Filtrar las horas inválidas\n",
        "horas_invalidas = df[~df[\"Hora válida\"]]\n",
        "\n",
        "if horas_invalidas.empty:\n",
        "    print(\"Todas las horas son válidas.\")\n",
        "else:\n",
        "    print(\"Horas inválidas encontradas:\")\n",
        "    print(horas_invalidas[[\"Fecha de atención\", \"Hora\"]])\n",
        "\n",
        "# Si no hay problemas con las horas, convertirlas a datetime.time para análisis adicional\n",
        "if horas_invalidas.empty:\n",
        "    df[\"Hora\"] = pd.to_datetime(df[\"Hora\"], format=\"%H:%M\").dt.time\n",
        "\n",
        "# Mostrar estadística de las horas\n",
        "if horas_invalidas.empty:\n",
        "    print(\"Hora más temprana:\", df[\"Hora\"].min())\n",
        "    print(\"Hora más tardía:\", df[\"Hora\"].max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7u2cAMsh4ZXl"
      },
      "source": [
        "Estudiamos los niveles de triaje, primero veremos cuantos niveles de triaje tenemos. Esto nos serivira para ver si hay alguno que no concuerde"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2vVfLeZ4aEw",
        "outputId": "d0f1b4ff-4d95-4b31-845b-177016af44f2"
      },
      "outputs": [],
      "source": [
        "print(df[\"Nivel de triaje\"].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsifmR1tt6Z-"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R37bOd51t6ri",
        "outputId": "9350000c-0405-460d-d4c3-2c529bfffa75"
      },
      "outputs": [],
      "source": [
        "print(df[\"Nivel de triaje\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVaJYDaluu2H"
      },
      "source": [
        "Ahora vamos a entrar más en detalle en los datos que hay dentro del Nivel de triaje, podemos ver la cantidad de datos, la media de la edad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CLcDcatuvJx",
        "outputId": "80f8b83e-ade4-45e5-e1a6-f3e7b1a34c1a"
      },
      "outputs": [],
      "source": [
        "# Filtrar filas donde \"Nivel de triaje\" sea NaN\n",
        "df_nivel_triaje_nan = df[df[\"Nivel de triaje\"].isna()]\n",
        "\n",
        "# Configurar Pandas para mostrar todo en una línea\n",
        "pd.set_option(\n",
        "    \"display.expand_frame_repr\", False\n",
        ")  # Evita que se divida en varias líneas\n",
        "pd.set_option(\"display.max_columns\", None)  # Muestra todas las columnas sin truncarlas\n",
        "\n",
        "print(\"Descripción de los datos:\")\n",
        "print(df_nivel_triaje_nan.describe().T)  # Transponer para verlo en línea\n",
        "\n",
        "print(\"\\nBase de datos:\")\n",
        "print(\n",
        "    df_nivel_triaje_nan.head().to_string(index=False)\n",
        ")  # Evita que se muestren los índices\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKrlSHbprWO8"
      },
      "source": [
        "Observamos que en los primeros datos se repiten el mismo año, ámbito de procedencia y zona de salud, por lo que vamos a verificar si el nivel de triaje \"Desconocido\" solo aparece cuando se cumple alguna de estas condiciones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw1w6OLerIjY",
        "outputId": "835dbb84-871c-4861-aa90-bbd2d6b0f8a7"
      },
      "outputs": [],
      "source": [
        "print(df_nivel_triaje_nan[\"Año\"].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW-ls1AKrCnM",
        "outputId": "1aac7494-c7c8-4743-a96a-f7c1868b5b24"
      },
      "outputs": [],
      "source": [
        "print(df_nivel_triaje_nan[\"Urbano\"].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrHdIVPYqx8Y",
        "outputId": "71e00395-e651-4ef9-9664-43be2c72d2f9"
      },
      "outputs": [],
      "source": [
        "print(df_nivel_triaje_nan[\"Zona Básica de Salud\"].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_9CR76X3-QJ"
      },
      "source": [
        "Ahora analizamos la variable 'Sexo' y observamos que hay más datos de mujeres que de hombres. Esta diferencia en la distribución de los datos debe ser considerada al momento de realizar el proyecto y extraer conclusiones, ya que podría influir en los resultados y en la interpretación de los análisis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "9FW1Phc33TnU",
        "outputId": "989aa950-7f0d-43a8-baee-c5bb4d6a8e46"
      },
      "outputs": [],
      "source": [
        "genero_counts = df[\"Hombre\"].value_counts(dropna=False)\n",
        "\n",
        "# Crear los colores para cada categoría\n",
        "colors = {1: \"blue\", 0: \"pink\", None: \"gray\"}\n",
        "\n",
        "# Crear el gráfico de barras\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(\n",
        "    genero_counts.index.astype(str),\n",
        "    genero_counts.values,\n",
        "    color=[colors.get(x, \"gray\") for x in genero_counts.index],\n",
        ")\n",
        "plt.title(\"Distribución de Género en la Base de Datos\", fontsize=16)\n",
        "plt.xlabel(\"Género\", fontsize=12)\n",
        "plt.ylabel(\"Cantidad\", fontsize=12)\n",
        "plt.xticks(rotation=0)\n",
        "plt.grid(axis=\"y\", alpha=0.3)\n",
        "\n",
        "# Agregar etiquetas a las barras\n",
        "for i, count in enumerate(genero_counts.values):\n",
        "    plt.text(i, count + 100, str(count), ha=\"center\", fontsize=10)\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8AmDnQ2tWqL"
      },
      "source": [
        "Una vez hemos analizado todas las variables y eliminado los datos que no eran útiles o que podían sesgar el estudio, procedemos a examinar la información en profundidad para identificar patrones y extraer conclusiones relevantes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsRTJpszcYgs"
      },
      "source": [
        "Ahora vamos a convertir tambien abinario el Ámbito de procedencia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z7xIvhkLUOh"
      },
      "source": [
        "####**6. Eliminación de Nans**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIVOa2J6YRoe"
      },
      "outputs": [],
      "source": [
        "# Filtrar eliminando solo los meses de enero a abril de 2021\n",
        "df = df[\n",
        "    ~(\n",
        "        (df[\"Fecha de atención\"].dt.year == 2021)\n",
        "        & (df[\"Fecha de atención\"].dt.month < 5)\n",
        "    )\n",
        "]\n",
        "\n",
        "# Filtrar solo los registros con edades válidas (entre 0 y 117 años)\n",
        "df = df[(df[\"Edad\"] >= 0) & (df[\"Edad\"] <= 117)]\n",
        "\n",
        "# Eliminamos las filas donde Nivel de triaje es Nan\n",
        "df = df.dropna(subset=[\"Nivel de triaje\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2P_8tIZ8rTM4"
      },
      "source": [
        "##Análisis de datos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "8JCQI7ptvnrM",
        "outputId": "485189cb-d3fc-4e05-bfd4-aed5f5430902"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn668-NY94Hh"
      },
      "source": [
        "Vamos a analizar la distribución de los pacientes por mes para identificar posibles ciclos, tendencias o patrones en la cantidad de atenciones registradas. Esto nos permitirá detectar si hay días con mayor afluencia de pacientes, estacionalidades recurrentes o tendencias a lo largo del tiempo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "id": "dpgMOn-v2dgq",
        "outputId": "54c95be9-d85e-47ca-ec1c-20c7176d5b06"
      },
      "outputs": [],
      "source": [
        "# Extraer el año y el mes para clasificar los datos\n",
        "df[\"Año\"] = df[\"Fecha de atención\"].dt.year\n",
        "df[\"Mes\"] = df[\"Fecha de atención\"].dt.month\n",
        "\n",
        "# Agrupar por mes y año\n",
        "pacientes_por_mes = df.groupby([\"Mes\", \"Año\"]).size().unstack()\n",
        "\n",
        "# Crear el gráfico con líneas superpuestas por año\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "for year in pacientes_por_mes.columns:\n",
        "    plt.plot(\n",
        "        pacientes_por_mes.index,\n",
        "        pacientes_por_mes[year],\n",
        "        marker=\"o\",\n",
        "        linestyle=\"-\",\n",
        "        label=str(year),\n",
        "    )\n",
        "\n",
        "plt.xlabel(\"Mes\", fontsize=12)\n",
        "plt.ylabel(\"Número de Pacientes\", fontsize=12)\n",
        "plt.title(\"Comparación de Pacientes por Mes en Distintos Años\", fontsize=16)\n",
        "plt.legend(title=\"Año\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xticks(\n",
        "    ticks=range(1, 13),\n",
        "    labels=[\n",
        "        \"Ene\",\n",
        "        \"Feb\",\n",
        "        \"Mar\",\n",
        "        \"Abr\",\n",
        "        \"May\",\n",
        "        \"Jun\",\n",
        "        \"Jul\",\n",
        "        \"Ago\",\n",
        "        \"Sep\",\n",
        "        \"Oct\",\n",
        "        \"Nov\",\n",
        "        \"Dic\",\n",
        "    ],\n",
        ")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DodvXSW8A0ep"
      },
      "source": [
        "Observamos que febrero suele ser el mes con menor cantidad de pacientes, probablemente debido a que tiene menos días. También detectamos una caída en el número de pacientes en junio y septiembre. La disminución en junio podría estar relacionada con el inicio del verano, cuando muchas personas comienzan sus vacaciones y la actividad en las ciudades disminuye, lo que podría reducir la afluencia a los servicios de urgencias. En septiembre, la vuelta a la rutina puede limitar el tiempo disponible para acudir a urgencias en casos de enfermedades leves.  \n",
        "\n",
        "A continuación, generaremos la misma gráfica, pero con los datos normalizados para evitar que la menor cantidad de días en febrero influya en la interpretación. Ajustaremos la proporción de pacientes para que todos los meses se consideren de 30 días, permitiéndonos extraer conclusiones más precisas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "9CUqWR4cvQmx",
        "outputId": "0b5e96b4-9174-4715-dcdb-9d813fe7012e"
      },
      "outputs": [],
      "source": [
        "# Contar el número de pacientes por mes en cada año\n",
        "pacientes_por_mes = df.groupby([\"Año\", \"Mes\"]).size()\n",
        "\n",
        "# Obtener el número de días únicos en cada mes del conjunto de datos\n",
        "dias_en_cada_mes = df.groupby([\"Año\", \"Mes\"])[\"Fecha de atención\"].nunique()\n",
        "\n",
        "# Ajustar los valores como si cada mes tuviera 30 días\n",
        "pacientes_normalizados = (pacientes_por_mes / dias_en_cada_mes) * 30\n",
        "\n",
        "# Crear el gráfico con líneas superpuestas por año\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "for year in pacientes_normalizados.index.get_level_values(0).unique():\n",
        "    datos_anuales = pacientes_normalizados.xs(\n",
        "        year, level=0\n",
        "    )  # Extraer datos de cada año\n",
        "    plt.plot(\n",
        "        datos_anuales.index,\n",
        "        datos_anuales.values,\n",
        "        marker=\"o\",\n",
        "        linestyle=\"-\",\n",
        "        label=str(year),\n",
        "    )\n",
        "\n",
        "plt.xlabel(\"Mes\", fontsize=12)\n",
        "plt.ylabel(\"Número de Pacientes (Normalizado a 30 días)\", fontsize=12)\n",
        "plt.title(\n",
        "    \"Comparación de Pacientes por Mes en Distintos Años (Normalizado)\", fontsize=16\n",
        ")\n",
        "plt.legend(title=\"Año\")\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xticks(\n",
        "    ticks=range(1, 13),\n",
        "    labels=[\n",
        "        \"Ene\",\n",
        "        \"Feb\",\n",
        "        \"Mar\",\n",
        "        \"Abr\",\n",
        "        \"May\",\n",
        "        \"Jun\",\n",
        "        \"Jul\",\n",
        "        \"Ago\",\n",
        "        \"Sep\",\n",
        "        \"Oct\",\n",
        "        \"Nov\",\n",
        "        \"Dic\",\n",
        "    ],\n",
        ")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqLql_9MC9UE",
        "outputId": "fff14f27-f08e-4588-eba4-9cec50168270"
      },
      "outputs": [],
      "source": [
        "pd.set_option(\"display.expand_frame_repr\", False)  # Evita la división de columnas\n",
        "\n",
        "# Contar el número de pacientes por mes en cada año\n",
        "pacientes_por_mes = df.groupby([\"Año\", \"Mes\"]).size()\n",
        "\n",
        "# Obtener el número de días únicos en cada mes del conjunto de datos\n",
        "dias_en_cada_mes = df.groupby([\"Año\", \"Mes\"])[\"Fecha de atención\"].nunique()\n",
        "\n",
        "# Ajustar los valores como si cada mes tuviera 30 días\n",
        "pacientes_normalizados = (pacientes_por_mes / dias_en_cada_mes) * 30\n",
        "\n",
        "# Encontrar el mes con más y menos pacientes por cada año\n",
        "mes_max_pacientes = pacientes_normalizados.groupby(level=0).idxmax()\n",
        "mes_min_pacientes = pacientes_normalizados.groupby(level=0).idxmin()\n",
        "\n",
        "# Obtener la cantidad de pacientes normalizados para cada mes máximo y mínimo\n",
        "cantidad_max_pacientes = pacientes_normalizados.loc[mes_max_pacientes.values].values\n",
        "cantidad_min_pacientes = pacientes_normalizados.loc[mes_min_pacientes.values].values\n",
        "\n",
        "# Crear un DataFrame con los resultados y las cantidades correspondientes\n",
        "resultados = pd.DataFrame(\n",
        "    {\n",
        "        \"Año\": mes_max_pacientes.index,\n",
        "        \"Mes con más pacientes\": [\n",
        "            m[1] for m in mes_max_pacientes.values\n",
        "        ],  # Extraer solo el mes\n",
        "        \"Cantidad más pacientes (Normalizada)\": cantidad_max_pacientes,\n",
        "        \"Mes con menos pacientes\": [\n",
        "            m[1] for m in mes_min_pacientes.values\n",
        "        ],  # Extraer solo el mes\n",
        "        \"Cantidad menos pacientes (Normalizada)\": cantidad_min_pacientes,\n",
        "    }\n",
        ")\n",
        "\n",
        "# Mostrar resultados\n",
        "print(resultados)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbrcSldeuLz5",
        "outputId": "4f559a6d-0ed1-40db-ce5b-4ca82a04b6e5"
      },
      "outputs": [],
      "source": [
        "# Ordenar los meses con más pacientes de mayor a menor cantidad\n",
        "meses_ordenados = pacientes_normalizados.sort_values(ascending=False).reset_index()\n",
        "meses_ordenados.columns = [\"Año\", \"Mes\", \"Cantidad de Pacientes (Normalizada)\"]\n",
        "\n",
        "# Mostrar resultados\n",
        "print(meses_ordenados)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vExq2_qbuVLL",
        "outputId": "756692aa-dfd4-4ef3-aae6-86ade22d4859"
      },
      "outputs": [],
      "source": [
        "df[\"Día\"] = df[\"Fecha de atención\"].dt.day\n",
        "\n",
        "# Contar el número de pacientes por día y mes en cada año\n",
        "pacientes_por_dia_mes = df.groupby([\"Año\", \"Mes\", \"Día\"]).size()\n",
        "\n",
        "# Encontrar el día y mes con menos pacientes para cada año\n",
        "dia_mes_menos_pacientes = pacientes_por_dia_mes.groupby(\"Año\").idxmin()\n",
        "cantidad_menos_pacientes = pacientes_por_dia_mes.groupby(\"Año\").min()\n",
        "\n",
        "# Crear un DataFrame con los resultados\n",
        "resultado_menos = pd.DataFrame(\n",
        "    {\n",
        "        \"Día y Mes con menos pacientes\": dia_mes_menos_pacientes,\n",
        "        \"Cantidad de pacientes\": cantidad_menos_pacientes,\n",
        "    }\n",
        ")\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(resultado_menos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-eMTV9lTIgT",
        "outputId": "8147ddc3-2049-413a-f5a8-28c858e452e5"
      },
      "outputs": [],
      "source": [
        "dia_mes_mas_pacientes = pacientes_por_dia_mes.groupby(\"Año\").idxmax()\n",
        "cantidad_mas_pacientes = pacientes_por_dia_mes.groupby(\"Año\").max()\n",
        "\n",
        "resultado_mas = pd.DataFrame(\n",
        "    {\n",
        "        \"Día y Mes con mas pacientes\": dia_mes_mas_pacientes,\n",
        "        \"Cantidad de pacientes\": cantidad_mas_pacientes,\n",
        "    }\n",
        ")\n",
        "\n",
        "print(resultado_mas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "dQHnIcNcWqeZ",
        "outputId": "413a5127-d210-40e1-b92c-52455d9e48ad"
      },
      "outputs": [],
      "source": [
        "# Asegurar que la columna de fecha esté en formato datetime\n",
        "df[\"Fecha de atención\"] = pd.to_datetime(df[\"Fecha de atención\"], errors=\"coerce\")\n",
        "\n",
        "# Eliminar valores nulos en Edad y Nivel de Triaje\n",
        "df = df.dropna(subset=[\"Edad\", \"Nivel de triaje\"])\n",
        "\n",
        "# Convertir Nivel de Triaje a string para evitar errores de categorización\n",
        "df[\"Nivel de triaje\"] = df[\"Nivel de triaje\"].astype(str)\n",
        "\n",
        "# Crear un boxplot para visualizar la distribución de edades por nivel de triaje\n",
        "plt.figure(figsize=(12, 6))\n",
        "df.boxplot(\n",
        "    column=\"Edad\", by=\"Nivel de triaje\", grid=False, vert=False, patch_artist=True\n",
        ")\n",
        "plt.title(\"Distribución de Edades por Nivel de Triaje\")\n",
        "plt.xlabel(\"Edad\")\n",
        "plt.ylabel(\"Nivel de Triaje\")\n",
        "plt.suptitle(\"\")  # Eliminar el título automático de pandas\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmeJGGpXQWhd"
      },
      "source": [
        "##Entrenamiento de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbtr8BbjQhh4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MualDnX1Sxx5"
      },
      "outputs": [],
      "source": [
        "df[\"Nivel de triaje\"] = pd.to_numeric(\n",
        "    df[\"Nivel de triaje\"], errors=\"coerce\"\n",
        ")  # Convierte strings a números y NaN a NaN\n",
        "df[\"Nivel de triaje\"] = df[\"Nivel de triaje\"].astype(int)  # Convertir a entero\n",
        "\n",
        "df[\"Edad\"] = pd.to_numeric(df[\"Edad\"], errors=\"coerce\")\n",
        "df[\"Edad\"] = df[\"Edad\"].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "wWO0NdU6XXgW",
        "outputId": "23366f21-1e86-46db-dda4-30a1dcd96553"
      },
      "outputs": [],
      "source": [
        "# Lista de columnas relacionadas con el tiempo que queremos excluir\n",
        "columnas_excluir = [\n",
        "    \"Hora del día\",\n",
        "    \"Día del año\",\n",
        "    \"Mes del año\",\n",
        "    \"Hora_sin\",\n",
        "    \"Hora_cos\",\n",
        "    \"Día_sin\",\n",
        "    \"Día_cos\",\n",
        "    \"Mes_sin\",\n",
        "    \"Mes_cos\",\n",
        "    \"Año\",\n",
        "    \"Día\",\n",
        "    \"Mes\",\n",
        "]\n",
        "\n",
        "# Seleccionar solo las columnas numéricas, excluyendo las de tiempo\n",
        "df_numerico_filtrado = df.select_dtypes(include=[\"number\"]).drop(\n",
        "    columns=columnas_excluir, errors=\"ignore\"\n",
        ")\n",
        "\n",
        "# Calcular la matriz de correlación\n",
        "correlaciones_filtradas = df_numerico_filtrado.corr()\n",
        "\n",
        "# Visualizar la matriz de correlación sin las variables de tiempo\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(\n",
        "    correlaciones_filtradas, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5\n",
        ")\n",
        "plt.title(\"Matriz de Correlación sin Variables de Tiempo\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "2YjymFiJY24M",
        "outputId": "e0216a54-4d84-4e76-fc76-744d6da3984c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- 1️⃣ DEFINIR VARIABLES ---\n",
        "target = \"Nivel de triaje\"  # Variable objetivo\n",
        "X = df.drop(columns=[target])  # Variables predictoras\n",
        "y = df[target]  # Valores de la variable objetivo\n",
        "\n",
        "# --- 2️⃣ ELIMINAR COLUMNAS NO NUMÉRICAS / CONVERTIR FORMATO ---\n",
        "# Revisar si hay columnas de tipo datetime\n",
        "datetime_cols = X.select_dtypes(include=[\"datetime\"]).columns\n",
        "print(\"Columnas datetime encontradas:\", datetime_cols.tolist())\n",
        "\n",
        "# Convertir fechas a timestamp (segundos desde 1970)\n",
        "for col in datetime_cols:\n",
        "    X[col] = X[col].astype(\"int64\") // 10**9\n",
        "\n",
        "# Revisar si hay columnas categóricas (no numéricas)\n",
        "non_numeric_cols = X.select_dtypes(exclude=[\"number\"]).columns\n",
        "print(\"Columnas categóricas encontradas:\", non_numeric_cols.tolist())\n",
        "\n",
        "# Convertir variables categóricas a numéricas con One-Hot Encoding\n",
        "if len(non_numeric_cols) > 0:\n",
        "    X = pd.get_dummies(X, columns=non_numeric_cols)\n",
        "\n",
        "# --- 3️⃣ DIVIDIR EN CONJUNTOS DE ENTRENAMIENTO Y PRUEBA ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# --- 4️⃣ CREAR Y ENTRENAR EL MODELO ---\n",
        "modelo = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "modelo.fit(X_train, y_train)\n",
        "\n",
        "# --- 5️⃣ HACER PREDICCIONES ---\n",
        "y_pred = modelo.predict(X_test)\n",
        "\n",
        "# --- 6️⃣ EVALUAR EL MODELO ---\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Precisión del modelo: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6BhBCWffPU-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
